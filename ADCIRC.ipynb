{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show how storm perturbations affect storm surge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read multiple directories containing output from ADCIRC and produced by these NCL scripts\n",
    "<pre>\n",
    "/glade/p/work/ahijevyc/ADCIRC/bulge_timeseries.ncl  \n",
    "/glade/p/work/ahijevyc/ADCIRC/perfect_cntl.ncl\n",
    "</pre>\n",
    "These directories can hold different speed perturbations, veer perturbations, vmax, or rmax perturbations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed plots in web page. No floating window.\n",
    "%matplotlib inline\n",
    "# svg increases resolution when you zoom in (Ctrl-+); png does not.\n",
    "# Use svg format (scalable vector graphics) for plots in web page, not png\n",
    "%config InlineBackend.figure_formats=['png']\n",
    "timestamp = True # \"created by\" timestamp in lower-left corner\n",
    "dpi = 300\n",
    "\n",
    "savfig_dict = {\"dpi\":dpi, \"timestamp\": timestamp} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trouble on cheyenne?\n",
    "try removing ~ahijevyc/lib/python2.7/site-packages from PYTHONPATH\n",
    "load these modules before start-notebook\n",
    "  1) ncarenv/1.2   2) intel/17.0.1   3) ncarcompilers/0.4.1   4) mpt/2.15f   5) netcdf/4.4.1.1   6) python/2.7.13   7) numpy/1.13.3   8) netcdf4-python/1.2.7   9) jupyter/5.0.0  10) matplotlib/2.0.2  11) cf_units/1.1.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geyser/caldera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source /glade/p/work/ahijevyc/my*/bin/activate.csh<br>\n",
    "module load adcirc_dav<br>\n",
    "<pre>Currently Loaded Modules:\n",
    "  1) ncarenv/1.2        4) ncarcompilers/1.0    7) pygrib/2.0.0           10) pyzmq/16.0.2     13) scipy/0.14.0        16) pyside/1.1.2\n",
    "  2) ncarbinlibs/1.1    5) netcdf/4.4.1.1       8) numpy/1.8.1            11) jupyter/5.0.0    14) bottleneck/0.8.0    17) pandas/0.14.0\n",
    "  3) intel/16.0.3       6) python/2.7.7         9) netcdf4python/1.1.1    12) numexpr/2.4      15) matplotlib/1.3.1    18) tornado/4.4.3\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import dates\n",
    "import glob, sys, os, re, urllib2\n",
    "from netCDF4 import Dataset, chartostring\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import cf_units # Provision of wrapper class to support UDUNITS-2, netcdftime calendar\n",
    "\n",
    "#plt.rcParams.update({'font.size': 12})\n",
    "#plt.rcParams.update({'lines.markersize': 8})\n",
    "from mysavfig import mysavfig\n",
    "import cache\n",
    "\n",
    "# Allow the program to be stopped and debugged.\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define Storm Class and Perturbation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class storm:\n",
    "    # Each storm is initiated with a name and a domain.\n",
    "    def __init__(self, name, domain):\n",
    "        self.name = name\n",
    "        # directory containing all the perturbation subdirectories.\n",
    "        self.basedir = '/glade/work/ahijevyc/ADCIRC/'+name+'/'\n",
    "        self.domain = domain\n",
    "        self.control_str = 'control'\n",
    "        \n",
    "        knots = cf_units.Unit('knots')\n",
    "        if name == 'IKE':\n",
    "            self.landfall = {\"time\": dt.datetime(2008,9,13,7),\n",
    "                            \"vmax\": knots.convert(95, 'm/s'),\n",
    "                            \"mslp\": 950\n",
    "                            }\n",
    "        if name == 'CHARLEY':\n",
    "            self.landfall = {\"time\": dt.datetime(2004,8,13,19),\n",
    "                            \"vmax\": knots.convert(130, 'm/s'),\n",
    "                            \"mslp\": 941\n",
    "                            }\n",
    "            self.landfall2 = {\"time\": dt.datetime(2004,8,13,20),\n",
    "                            \"vmax\": knots.convert(125, 'm/s'),\n",
    "                            \"mslp\": 942\n",
    "                            }\n",
    "        if name == 'HARVEY':\n",
    "            self.landfall = {\"time\": dt.datetime(2017,8,26,6),\n",
    "                            \"vmax\": knots.convert(100, 'm/s'),\n",
    "                            \"mslp\": 950\n",
    "                            }\n",
    "            self.control_str = 'control_nws19'\n",
    "\n",
    "        if name == 'IRMA':\n",
    "            self.landfall = {\"time\": dt.datetime(2017,9,10,12),\n",
    "                            \"vmax\": knots.convert(115, 'm/s'),\n",
    "                            \"mslp\": 931\n",
    "                            }\n",
    "            self.control_str = 'control_nws19'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Perturbation:\n",
    "    # Called by Perturbations\n",
    "    def __init__(self, path, storm, Ithresh, minus_astronomical_tide, dryland):\n",
    "        j = os.path.basename(path)\n",
    "\n",
    "        if j[0:7] == 'control':\n",
    "            self.value = j\n",
    "            self.valuelabel = j\n",
    "        elif 'ens_' in j:\n",
    "            self.valuelabel = re.findall(r'ens_(\\d+)', j)[0]\n",
    "            self.value = int(self.valuelabel)\n",
    "        elif 'WRF' in j:\n",
    "            self.valuelabel = j[19:21]\n",
    "            self.value = j[4:]\n",
    "        else:\n",
    "            # Find last index of + or - sign\n",
    "            n = max([j.find('+'), j.find('-')])\n",
    "            if n == -1:\n",
    "                self.value = re.findall(r'\\d+', j)[0]\n",
    "                # good for 2017090600.uni\n",
    "                if self.value[0:3] == '201':\n",
    "                    self.value = dt.datetime.strptime(self.value,'%Y%m%d%H')\n",
    "            else:\n",
    "                j = j[n:]\n",
    "                self.value = float(j)\n",
    "        self.path = path\n",
    "        \n",
    "        timeseries_search_str = path + \\\n",
    "            '/*.minus_astronomical_tide'+str(minus_astronomical_tide)+\\\n",
    "            '_'+Ithresh+'.'+dryland+'.'+storm.domain+'.timeseries.nc'\n",
    "\n",
    "        tsfile = glob.glob(timeseries_search_str)\n",
    "        if len(tsfile) != 1:\n",
    "            print \"Did not find one file matching \"+timeseries_search_str\n",
    "        \n",
    "        # Fill in these attributes of Perturbation object at time of max Inundation Volume:\n",
    "        # volume in control zone, length scale, inundation area, average depth\n",
    "        print tsfile[0]\n",
    "        fh = Dataset(tsfile[0], mode='r')\n",
    "        inund = fh.variables['inundation_volume'][:]\n",
    "        imax = np.argmax(inund)\n",
    "        \n",
    "        self.max_vol         = inund[imax]\n",
    "\n",
    "        # True = old way (get value at time of max inundation volume over whole domain)\n",
    "        self.fixed_time      = False\n",
    "        if self.fixed_time:\n",
    "            self.max_vol_in_ctrl = fh.variables['volume_in_ctrl'][imax]\n",
    "            self.length_scale    = fh.variables['length_scale'][imax]\n",
    "            self.area            = fh.variables['inundation_area'][imax]\n",
    "            self.depth           = fh.variables['average_depth'][imax]\n",
    "        else: \n",
    "            # new way (look for max value over all times, not just time of max inundation volume over\n",
    "            # whole domain)\n",
    "            # For example, the time with the most water in the ctrl zone is not necessarily the same\n",
    "            # as the time when the total inundation volume is greatest.\n",
    "            # Use [:]. or else you sometimes get _FillValue.\n",
    "            self.max_vol_in_ctrl = np.max(fh.variables['volume_in_ctrl'][:])\n",
    "            self.length_scale    = np.max(fh.variables['length_scale'][:])\n",
    "            self.area            = np.max(fh.variables['inundation_area'][:])\n",
    "            self.depth           = np.max(fh.variables['average_depth'][:])\n",
    "\n",
    "\n",
    "        self.inund           = inund\n",
    "        \n",
    "        # Ignore time zone (used to be \"UTC\" but now it is \"-0:00\") Had to manually\n",
    "        # adjust netcdf time attributes when base time is not 0Z.\n",
    "        # Fixed issues with adcirc starting at 18Z for Irma.\n",
    "        simple_dt = \" \".join(fh.variables['time'].base_date.split()[0:2])\n",
    "        base_date    = dt.datetime.strptime(simple_dt, \"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        self.time = [base_date + dt.timedelta(0,t) for t in fh.variables['time']]\n",
    "        fh.close()\n",
    "\n",
    "        # if vmax+3, keep +3 part\n",
    "        if isinstance(self.value,float):\n",
    "            self.valuelabel = '{0:+g}'.format(self.value)\n",
    "        # If datetime, keep month/day\n",
    "        elif isinstance(self.value,dt.datetime):\n",
    "            self.valuelabel = self.value.strftime('%m/%d')\n",
    "        #if self.value == 0:\n",
    "            #self.valuelabel = '' # Uncomment to not include control in legends\n",
    "\n",
    "        # Also get max water level field. Find node with highest inundation below 6.5 m\n",
    "        mxfile = path+'/maxele.63.nc'\n",
    "        Athresh = 6.5\n",
    "\n",
    "        try:\n",
    "            fh = Dataset(mxfile, mode='r')\n",
    "        except:\n",
    "            if not os.path.exists(mxfile):\n",
    "                print \"maxele.63.nc not in\", path\n",
    "            if os.path.islink(mxfile) and not os.path.exists(os.readlink(mxfile)):\n",
    "                print \"maxele.63.nc symbolic link broken in\", path\n",
    "            print \"could not read\", self.mxfile    \n",
    "            self.mxfile = None\n",
    "            maxele = None\n",
    "            A = None\n",
    "            value = None\n",
    "            lon = None\n",
    "            lat = None\n",
    "        else:\n",
    "            self.mxfile = mxfile\n",
    "            maxele = fh.variables['zeta_max'][:]\n",
    "            # Find a node (largest index) with max water height < 6.5m, south of 40°N\n",
    "            A = np.argmax(maxele * (maxele<Athresh) * (fh.variables['y'][:]<40))\n",
    "            lon = fh.variables['x'][A]\n",
    "            lat = fh.variables['y'][A]\n",
    "            value = maxele[A]\n",
    "\n",
    "        fh.close()\n",
    "\n",
    "        self.maxele = maxele\n",
    "        self.pointA = {\"index\":A, \"value\":value, \"thresh\":Athresh, \"lon\":lon, \"lat\":lat}\n",
    "        print path\n",
    "\n",
    "        \n",
    "class Perturbations:\n",
    "    \n",
    "    # Returns an ordered list of perturbation instances in increasing order. \n",
    "    \n",
    "    def __init__(self, storm, ptype, units=\"\", xlabel=\"\", Ithresh='1.00m', \n",
    "                 minus_astronomical_tide=False, dryland='MHHW'):\n",
    "\n",
    "        # Map perturbation type to subdirectory name.\n",
    "        if ptype == 'veers' :\n",
    "            pstr = 'veer'\n",
    "            if storm.name == 'HARVEY':\n",
    "                pstr = 'track'\n",
    "        elif ptype == 'speeds':\n",
    "            pstr = 'speed'\n",
    "        elif ptype == 'vmaxes':\n",
    "            pstr = 'vmax_PcAdjust'\n",
    "            if storm.name in ['IRMA','HARVEY'] :\n",
    "                pstr = 'vmax'\n",
    "        elif ptype == 'rmaxes':\n",
    "            pstr = 'rmax'\n",
    "        else:\n",
    "            print \"Unknown perturbation type\", name\n",
    "            sys.exit(1)\n",
    "        \n",
    "        control_str = 'control'\n",
    "        if storm.name in ['IRMA','HARVEY']:\n",
    "            pstr = pstr + '_nws19'\n",
    "            control_str = 'control_nws19'\n",
    "            \n",
    "        # find all the directories, scrape off numeric part, sort numerically\n",
    "        dirnames = glob.glob(storm.basedir+pstr+'[+-]*[0-9]')\n",
    "\n",
    "        self.storm   = storm\n",
    "        self.ptype   = ptype\n",
    "        self.units   = units\n",
    "        self.Ithresh = Ithresh\n",
    "        self.minus_astronomical_tide = minus_astronomical_tide\n",
    "\n",
    "        members = []\n",
    "        for i in dirnames:\n",
    "            members.append(Perturbation(i, storm, Ithresh, minus_astronomical_tide, dryland))\n",
    "            \n",
    "        self.members  = sorted(members, key=lambda x: x.value, reverse=False)\n",
    "        self.values          = [i.value for i in self.members]\n",
    "        self.dirnames        = [i.path for i in self.members]\n",
    "        self.area            = [i.area for i in self.members]\n",
    "        self.depth           = [i.depth for i in self.members]\n",
    "        self.domain          = storm.domain\n",
    "        self.dryland         = dryland\n",
    "        self.inund           = [i.inund for i in self.members]\n",
    "        self.length_scale    = [i.length_scale for i in self.members]\n",
    "        self.maxele          = [i.maxele for i in self.members]\n",
    "        self.max_vol_in_ctrl = [i.max_vol_in_ctrl for i in self.members]\n",
    "        self.max_vol         = [i.max_vol for i in self.members]\n",
    "        self.mxfile          = [i.mxfile for i in self.members]\n",
    "        self.pointA          = [i.pointA for i in self.members]\n",
    "        self.time            = [i.time for i in self.members]\n",
    "        self.valuelabels     = [i.valuelabel for i in self.members]\n",
    "        if units != \"\":\n",
    "            xlabel = \" (\"+units+\")\"\n",
    "        self.xlabel          = xlabel\n",
    "        self.index = 0\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        self.values = np.array(self.values)\n",
    "\n",
    "        # Get desc from attributes of length_scale variable in control run.\n",
    "        ifile = storm.basedir + control_str + '/' + control_str+ '.minus_astronomical_tide' + \\\n",
    "            str(minus_astronomical_tide) + '_' + Ithresh + '.' + dryland + '.' + storm.domain + '.timeseries.nc'\n",
    "        fh = Dataset(ifile, mode='r')\n",
    "        ls = fh.variables['length_scale']\n",
    "        self.desc = pstr + ' minus_astronomical_tide:' +str(minus_astronomical_tide) + \\\n",
    "            \" \" + dryland + '\\ninundation depth threshold: ' + \\\n",
    "            ls.depth_threshold +'\\nlength scale left side: ' + \\\n",
    "            str(ls.left_percentile) + '%; right: ' + str(ls.right_percentile) + '%'\n",
    "        fh.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "            \n",
    "    # Allow perturbations to be iterated over\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def next(self):\n",
    "        if self.index < len(self.values):\n",
    "            member = self.members[self.index]\n",
    "            self.index += 1\n",
    "            return member\n",
    "        else:\n",
    "            self.index = 0\n",
    "            raise StopIteration\n",
    "    \n",
    "    def get_xticks(self):\n",
    "\n",
    "        # x-axis may be converted from perturbation magnitude to something else.\n",
    "\n",
    "        # Convert veer perturbations to cross-track distance right of landfall (km)\n",
    "        # Convert speed perturbations to along-track distance at landfall (km)\n",
    "        # Keep vmax perturbation (kts)\n",
    "        # Keep rmax perturbation (%)\n",
    "\n",
    "        stormname = self.storm.name\n",
    "\n",
    "        if self.ptype == 'veers':\n",
    "            if 'IKE' in stormname:\n",
    "                # From https://docs.google.com/a/ucar.edu/spreadsheets/d/1_Y9dX2240jMZ1abgZt4E6Td-pODq6k3q8rxVKwz55Us/edit?usp=sharing\n",
    "                pert,dist = np.array([(-6,-250),(-5,-198),(-4,-157),(-3,-121),(-2,-97),(-1,-49),(-0.5,-24),\n",
    "                                      (0.,0.),(0.5,22),(1.0,44),(2.0,82),(3.0,135),(4.0,146),(5.0,170),\n",
    "                                      (6.0,199)]).T\n",
    "            if stormname == 'CHARLEY':\n",
    "                # https://docs.google.com/a/ucar.edu/spreadsheets/d/1gKj72PWl8g_0QAOCMZawT2c8QRfDa1DreanUWU4DC74/edit?usp=sharing\n",
    "                # Spreadsheet lists these from +4.5 to -4.5\n",
    "                pert = [-4.5, -3.5, -2.5, -1.5, -0.5, 0, 0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "                dist = [-343, -289, -153,  -63,  -15, 0,  32,  63, 102, 122, 134]\n",
    "            if stormname == 'IRMA':\n",
    "                # https://docs.google.com/a/ucar.edu/spreadsheets/d/1QtxUjO3qIXf2ySPRh0RPG51KasDUCQwmp4ac0hKG3zk/edit?usp=sharing\n",
    "                # Copied and pasted into vim window and edited to look like this.\n",
    "                pert,dist = np.array([(-7,-230), (-6,-195), (-5,-181), (-4,-136), (-3,-98), (-2,-63), (-1,-35),\n",
    "                                  (0,0), (1, 30), (2,60), (3,90), (4,128), (5,158), (6,188), (7,217)]).T\n",
    "            if stormname == 'HARVEY':\n",
    "                # https://docs.google.com/spreadsheets/d/1TBdFfGUwdJ9T5Oh7Kv2T7thGvZXeqU1Q_Laj0ztgN4U/edit?usp=sharing\n",
    "                pert,dist = np.array([(-7,-277.80), (-6,-255.58), (-5,-244.46), (-4,-118.53), (-3 ,-88.90),\n",
    "                                  (-2,-59.26), (-1,-29.63), (0,0.00), (1,31.48), (2,59.26), (3,96.30),\n",
    "                                  (4 ,118.53), (5 ,150.01), (6 ,177.79), (7 ,207.42)]).T\n",
    "\n",
    "\n",
    "        if self.ptype == 'speeds':\n",
    "            if 'IKE' in stormname:\n",
    "                # From https://docs.google.com/a/ucar.edu/spreadsheets/d/1_Y9dX2240jMZ1abgZt4E6Td-pODq6k3q8rxVKwz55Us/edit?usp=sharing\n",
    "                pert,dist = np.array([(-20,-401),(-15,-273),(-10,-173),(-5,-61),(0.,0.),(5,43),\n",
    "                                      (10,130),(15,248)]).T\n",
    "            if stormname == 'CHARLEY':\n",
    "                # From https://docs.google.com/a/ucar.edu/spreadsheets/d/1gKj72PWl8g_0QAOCMZawT2c8QRfDa1DreanUWU4DC74/edit?usp=sharing\n",
    "                pert = [ -15, -12.5,  -10, -7.5,   -5, -2.5, 0, 2.5,   5, 7.5,  10,  15]\n",
    "                dist = [-378,  -329, -260, -177, -116,  -35, 0,  94, 163, 220, 275, 348] # km\n",
    "            if stormname == 'IRMA':\n",
    "                # From https://docs.google.com/a/ucar.edu/spreadsheets/d/1QtxUjO3qIXf2ySPRh0RPG51KasDUCQwmp4ac0hKG3zk/edit?usp=sharing\n",
    "                # Copied and pasted into vim window and edited to look like this.\n",
    "                pert,dist = np.array([(-20,-314),(-15,-239), (-10,-159), (-5,-67), (0,0), (5,75), (10,154),\n",
    "                                      (15,200), (20,236)]).T\n",
    "            if stormname == 'HARVEY':\n",
    "                pert,dist = np.array([(-20,-125.936),(-15,-88.896),(-10,-64.82),(-5,-25.928),(0,0),(5,61.116),\n",
    "                                      (10,120.38),(15,164.828),(20,237.056)]).T\n",
    "\n",
    "\n",
    "        if self.ptype == 'vmaxes':\n",
    "            pert,dist = np.array([(-7,-28),(7,28)]).T\n",
    "\n",
    "        if self.ptype == 'rmaxes':\n",
    "            # Radius change of +100% error.\n",
    "            # Find landfall time in control/fort.22\n",
    "            # Find 34kt line. \n",
    "            # Look for max value in columns 35,36,37,38 (in nautical miles)\n",
    "            # Convert to km.\n",
    "            # IKE and CHARLEY from Kate Fossell's Feb 28 2017 email\n",
    "            if stormname ==    'IKE': rmax100 = 75.19 # km\n",
    "            if 'CHAR' in stormname:   rmax100 = 36.85 # km\n",
    "            if stormname ==   'IRMA': rmax100 = 60.93 # km\n",
    "            if stormname == 'HARVEY': rmax100 = 44.818 # km\n",
    "            pert,dist = zip(*[(-100.,-rmax100),(100.,rmax100)])\n",
    "\n",
    "\n",
    "        if np.min(pert) >= 0:\n",
    "            print \"no negative perturbations\", pert\n",
    "            print \"did you forget to negate the negative veers and speeds?\"\n",
    "            exit(2)\n",
    "\n",
    "        xticks = np.interp(self.values, pert, dist)\n",
    "        return xticks\n",
    "\n",
    "\n",
    "# Standard prefix for output filename.\n",
    "def oprefix(perturbations, ptype=False):\n",
    "    p_namestr = ''\n",
    "    if ptype == True:\n",
    "        p_namestr = '.' + perturbations.ptype\n",
    "    prefix =  perturbations.storm.basedir + perturbations.storm.name + \\\n",
    "    p_namestr + \\\n",
    "    '.minus_astronomical_tide' + str(perturbations.minus_astronomical_tide) + \\\n",
    "    '.' + perturbations.Ithresh + '.' + perturbations.domain\n",
    "    return prefix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create storm objects with domains (must have been created by NCL scripts already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IKE     = storm(name='IKE',     domain='stride10.-99.0E-87.0E25.0N31.0N')\n",
    "CHARLEY = storm(name=\"CHARLEY\", domain='stride02.-86.0E-78.0E24.2N30.0N')\n",
    "CHARIKE = storm(name='CHARIKE', domain='stride10.-99.0E-87.0E25.0N31.0N')\n",
    "IRMA_SW      = storm(name='IRMA',    domain='stride02.-88.0E-77.0E24.0N35.0NFloridaSW')\n",
    "IRMA_SWzoom2 = storm(name='IRMA',    domain='stride02.-83.0E-79.0E24.0N27.0NFloridaSW')\n",
    "IRMA_SWzoom4 = storm(name='IRMA',    domain='stride02.-82.3E-80.0E24.5N26.1NFloridaSW')\n",
    "IRMA_NEzoom3 = storm(name='IRMA',    domain='stride02.-82.0E-78.2E30.0N33.0NFloridaNE')\n",
    "IRMA_NE      = storm(name='IRMA',    domain='stride02.-88.0E-77.0E24.0N35.0NFloridaNE')\n",
    "\n",
    "\n",
    "\n",
    "HARVEY  = storm(name='HARVEY',  domain='stride02.-98.0E-92.2E24.8N30.5N')\n",
    "\n",
    "\n",
    "thisstorm = IRMA_NE\n",
    "\n",
    "def get_bounds(domain):\n",
    "    # domain is something like 'stride02.-99.0E-87.0E25.0N31.0N'\n",
    "    words =  domain.split('.')\n",
    "    stride = words[0]\n",
    "    lonmin = float(words[1]+'.'+words[2][0:1])\n",
    "    lonmax = float(words[2][2:]+'.'+words[3][0:1])\n",
    "    latmin = float(words[3][2:]+'.'+words[4][0:1])\n",
    "    latmax = float(words[4][2:]+'.'+words[5][0:1])\n",
    "    return lonmin, lonmax, latmin, latmax\n",
    "\n",
    "lonmin, lonmax, latmin, latmax = get_bounds(thisstorm.domain)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## special time-lagged ensemble for IRMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if thisstorm.name == 'IRMA':\n",
    "    if False:\n",
    "        dirnames = sorted(glob.glob(thisstorm.basedir+'ECMWF.2017090700.ens_*'))\n",
    "        members_title = \"ECMWF ensemble 2017090700\"\n",
    "    elif False:\n",
    "        members_title = \"MPAS uniform 15km mesh, ECMWF init. conditions\"\n",
    "    else:\n",
    "        dirnames = sorted(glob.glob(thisstorm.basedir+'WRF.2017090512.E??_*.27km3km'))\n",
    "        # members 33 and 39 blow up\n",
    "        dirnames.remove('/glade/work/ahijevyc/ADCIRC/IRMA/WRF.2017090512.EPS_33.27km3km')\n",
    "        dirnames.remove('/glade/work/ahijevyc/ADCIRC/IRMA/WRF.2017090512.EPS_39.27km3km')\n",
    "\n",
    "        members_title = 'WRF 2017090512 EPS 27km3km'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Ithresh = '1.00m'\n",
    "    minus_astronomical_tide = False\n",
    "    dryland  = 'MHHW'\n",
    "\n",
    "    # Start list of members with control\n",
    "    members = [Perturbation(thisstorm.basedir+thisstorm.control_str, thisstorm, Ithresh, minus_astronomical_tide, dryland)]\n",
    "    members=[]\n",
    "    for i in dirnames:        \n",
    "        members.append(Perturbation(i, thisstorm, Ithresh, minus_astronomical_tide, dryland))\n",
    "\n",
    "\n",
    "    dirnames        = [i.path for i in members]\n",
    "    area            = [i.area for i in members]\n",
    "    depth           = [i.depth for i in members]\n",
    "    inund           = [i.inund for i in members]\n",
    "    length_scale    = [i.length_scale for i in members]\n",
    "    maxele          = [i.maxele for i in members]\n",
    "    max_vol_in_ctrl = [i.max_vol_in_ctrl for i in members]\n",
    "    max_vol         = [i.max_vol for i in members]\n",
    "    mxfile          = [i.mxfile for i in members]\n",
    "    pointA          = [i.pointA for i in members]\n",
    "    time            = [i.time for i in members]\n",
    "    valuelabels     = [i.value for i in members]\n",
    "\n",
    "    members = sorted(members, key=lambda member: member.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print members[1].valuelabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time series from special time-lagged IRMA ensemble by MPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure variable is defined\n",
    "try:\n",
    "    members\n",
    "except NameError:\n",
    "    members = None\n",
    "if members:\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "    ax.set_title(members_title)\n",
    "    for pert in members:\n",
    "        line, = ax.plot(pert.time,pert.inund,label=pert.valuelabel,markersize=3,lw=1.)\n",
    "        \n",
    "        if isinstance(pert.value, str) and pert.value[0:7] == 'control':\n",
    "            line.set_linewidth(4)\n",
    "            line.set_color('k')\n",
    "        elif isinstance(pert.value, dt.datetime):\n",
    "            if pert.value > dt.datetime(2017,9,7):\n",
    "                line.set_marker('o')\n",
    "                line.set_markevery(1)\n",
    "        elif isinstance(pert.value, int):\n",
    "            markers = ['','o','^','s','x']\n",
    "            line.set_marker(markers[(pert.value-1)/10])\n",
    "            line.set_markevery(2)\n",
    "            \n",
    "        # label top of line\n",
    "        if pert.inund.max() > 0.2:\n",
    "            print pert.valuelabel, pert.time[np.argmax(pert.inund)], np.max(pert.inund)\n",
    "            ax.annotate(pert.valuelabel,\n",
    "            xy=(pert.time[np.argmax(pert.inund)], np.max(pert.inund)), xycoords='data',\n",
    "            xytext=(0, -0.1), textcoords='offset points', fontsize=2.5, color=line.get_color(),\n",
    "            horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "    units = 'inundation volume ($\\mathregular{km^3}$)'\n",
    "    ax.set_ylabel(units)\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.xaxis.set_major_formatter(dates.DateFormatter('%-m/%-d %-H'+'Z'))\n",
    "    ax.xaxis.set_major_locator(dates.HourLocator(byhour=[0,6,12,18]))\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    ax.set_xlabel(members[0].time[0].strftime(\"%Y\"))\n",
    "\n",
    "    # put legend\n",
    "    if len(members) > 10:\n",
    "        ax.legend(loc='best', fontsize=5,ncol=4)\n",
    "    else:\n",
    "        ax.legend(loc='best')\n",
    "    \n",
    "    plt.suptitle(thisstorm.name)\n",
    "\n",
    "    status = mysavfig(thisstorm.basedir+'/'+members_title.replace(' ','_').replace('\\n','.') + '.' \n",
    "                      + thisstorm.domain + '.timeseries.png', \n",
    "                      string = \" \".join([\"ensemble\", thisstorm.domain]), **savfig_dict )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perturbation(thisstorm.basedir+thisstorm.control_str, thisstorm, Ithresh, minus_astronomical_tide, dryland)\n",
    "for pert in members:\n",
    "    print pert.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define map_points() for Basemap plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "\n",
    "def map_points(ax, lon, lat, s=64, scalebuffer=1., colors='k', linewidth=0.5, resolution='i', \n",
    "               labels=None, **kwargs):\n",
    "    # Scatter plot on a map.\n",
    "    # Domain large enough to encompasses all the markers, plus a 3° longitude and 1° latitude buffer. \n",
    "    m = Basemap(lon_0=-90,lat_0=30,resolution=resolution,projection='stere',\\\n",
    "                llcrnrlat=np.amin(lat)-1.*scalebuffer,\\\n",
    "                urcrnrlat=np.amax(lat)+1.*scalebuffer,\\\n",
    "                llcrnrlon=np.amin(lon)-3.*scalebuffer,\\\n",
    "                urcrnrlon=np.amax(lon)+3.*scalebuffer,ax=ax)\n",
    "    m.drawcoastlines(linewidth=0.5)\n",
    "    m.drawmapboundary(fill_color='aqua')\n",
    "    # fill continents, set lake color same as ocean color.\n",
    "    m.fillcontinents(color='white',lake_color='aqua',zorder=0)\n",
    "    # draw parallels and meridians.\n",
    "    # label parallels on right and top\n",
    "    # meridians on bottom and left\n",
    "    parallels = np.arange(0.,81,1.)\n",
    "    # labels option turns off/on label. 4 element list for 4 sides: [left,right,top,bottom]\n",
    "    m.drawparallels(parallels,labels=[True,True,False,True])\n",
    "    meridians = np.arange(10.,351.,2.)\n",
    "    m.drawmeridians(meridians,labels=[True,True,False,True])\n",
    "    m.scatter(lon, lat, latlon=True, s=s, c=colors, linewidth=linewidth, **kwargs)\n",
    "    if labels:\n",
    "        for x, y, label in zip(lon, lat, labels):\n",
    "            ax.annotate(label, xy=m(x, y), ha='center', va='center', fontsize=5.)\n",
    "\n",
    "\n",
    "    return m\n",
    "\n",
    "def forecast_err_box(xmin, xmax, label, **kwargs):\n",
    "    # Called by forecast_err_boxes()\n",
    "    # Draw box from xmin to xmax, spanning the vertical.\n",
    "    # Label vertical lines too.\n",
    "    ax = kwargs['axes']\n",
    "    # Dont' change the xaxis range\n",
    "    ax.autoscale(False)\n",
    "    box = ax.axvspan(xmin, xmax, alpha=0.075, facecolor='red', **kwargs)\n",
    "    edgecolor = 'red'\n",
    "    box = ax.axvspan(xmin, xmax, alpha=0.2, facecolor=\"none\", edgecolor=edgecolor, lw=1.8, **kwargs)\n",
    "    labelL = ax.annotate(s=label, xy=(xmin,0.5), ha=\"center\", va=\"center\", xycoords=('data', 'axes fraction'), \n",
    "                         rotation=90, fontsize=12, annotation_clip=True, zorder=1, alpha=0.75, **kwargs)\n",
    "    labelR = ax.annotate(s=label, xy=(xmax,0.5), ha=\"center\", va=\"center\", xycoords=('data','axes fraction'), \n",
    "                         rotation=90, fontsize=12, annotation_clip=True, zorder=1, alpha=0.75, **kwargs)\n",
    "\n",
    "def forecast_err_boxes(ax, perturbation):\n",
    "    # Draw tranparent red boxes to illustrate typical forecast err for different lead times.\n",
    "\n",
    "    # clunky way to get nautical miles (multiply knots by hour)\n",
    "    nm = cf_units.Unit('knot') * cf_units.Unit('hour')\n",
    "\n",
    "    if perturbation.ptype == 'veers':\n",
    "        # list of (hour, nautical miles) tuples to define 2010-2014 cone from \n",
    "        # https://docs.google.com/a/ucar.edu/spreadsheets/d/1_Y9dX2240jMZ1abgZt4E6Td-pODq6k3q8rxVKwz55Us/edit?usp=sharing\n",
    "        fhr, radii = zip(*[(12,32),(24,52),(36,71),(48,90),(72,122),(96,170),(120,225)])\n",
    "        \n",
    "        # Convert nautical miles to km\n",
    "        radii = nm.convert(np.array(radii), cf_units.Unit('km'))\n",
    "        fhrboxes = [12,24,48,72]\n",
    "\n",
    "    if perturbation.ptype == 'speeds':\n",
    "        # list of (hour, km) tuples to define 2010-2014 cone estimated to be more than cross-track error from\n",
    "        # https://docs.google.com/a/ucar.edu/spreadsheets/d/1_Y9dX2240jMZ1abgZt4E6Td-pODq6k3q8rxVKwz55Us/edit?usp=sharing\n",
    "        fhr, radii = zip(*[(12,32),(24,52),(36,71),(48,90),(72,122),(96,170),(120,225)])\n",
    "        # Convert from nm to km\n",
    "        radii = nm.convert(np.array(radii), cf_units.Unit('km'))\n",
    "        fhrboxes = [12,24,48,72]\n",
    "\n",
    "    if perturbation.ptype == 'vmaxes':\n",
    "        # list of (hour, knots) tuples from NHC published stats \n",
    "        # https://drive.google.com/open?id=0B4GoIuq38OVyLTRhTkxmbE1YZVY1eU5xYlA3RlJWOHlyN3A0\n",
    "        fhr, radii = zip(*[(24,10),(48,15),(72,20)])\n",
    "        fhrboxes = fhr\n",
    "        \n",
    "    if perturbation.ptype == 'rmaxes':\n",
    "        # list of (hour, km) tuples Feb 10 2017 email from Kate Fossell\n",
    "        # Based on Cangialosi and Landsea (2016)\n",
    "        fhr, radii = zip(*[(12,37),(24,52),(36,60),(48,63),(72,68)])\n",
    "        fhrboxes = [12,24,48,72]\n",
    "        \n",
    "    try:\n",
    "        fhr\n",
    "    except NameError:\n",
    "        print \"no foreast lead time window for\", perturbation.name, perturbation.storm.name\n",
    "        return\n",
    "    # np.interp(x,xp,fp)\n",
    "    # x: x-coordinates of interpolated values\n",
    "    # xp: 1-D seq of floats. the x-coordinates of the data points\n",
    "    # fp: 1-D seq of floats or complex. The y-coordinates of the data points, same len as xp.\n",
    "    # Get errors assocated with fboxes list.\n",
    "    lefts = -np.interp(fhrboxes, fhr, radii)\n",
    "    rights = np.interp(fhrboxes, fhr, radii)\n",
    "    for box, left, right in zip(fhrboxes, lefts, rights):\n",
    "        junk = forecast_err_box(left, right, '%d-hr' % box, axes=ax)\n",
    "        \n",
    "def zeroLine(line, **kwargs):\n",
    "    line.axes.axvline(x=0, linestyle='dashed', color='black', zorder=1)\n",
    "    # Use np.isclose because of rmaxes, where zero tick is interpolated to a tiny non-zero value.\n",
    "    i0, = np.where(np.isclose(line.get_xdata(), 0))\n",
    "    line.axes.axhline(y=line.get_ydata()[i0], linestyle='dashed', color=line.get_color(), **kwargs)\n",
    "            \n",
    "def annotate_pts(perturbation, line):\n",
    "    for label, xypoints in zip(perturbation.valuelabels, line.get_xydata()):\n",
    "        line.axes.annotate(label, xy=xypoints, textcoords='offset points', xytext=(0,+4), \n",
    "                           ha='center', va='bottom', fontsize=6.5)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Control to NOAA Stations (IKE or IRMA )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# NOAA station data come from tidesandcurrents.noaa.gov\n",
    "def turl(id, begin_date, end_date, datum):\n",
    "    return \"http://tidesandcurrents.noaa.gov/api/datagetter?product=water_level&application=NOS.COOPS.TAC.WL&station=\"+\\\n",
    "        id+\"&begin_date=\"+begin_date+\"&end_date=\"+end_date+\"&datum=\"+datum+\"&units=metric&time_zone=GMT&format=csv\"\n",
    "\n",
    "if True and thisstorm.name in ['IKE','IRMA']:\n",
    "    fort61 = thisstorm.basedir+thisstorm.control_str+'/fort.61.nc'\n",
    "    print(\"opening\",fort61)\n",
    "    fh = Dataset(fort61, mode='r')\n",
    "    stations = chartostring(fh.variables['station_name'][:])\n",
    "    meshlon = fh.variables['x'][:]\n",
    "    meshlat = fh.variables['y'][:]\n",
    "    \n",
    "    \n",
    "    # Fixed issues with adcirc starting at 18Z for Irma by\n",
    "    # manually adjusting netcdf time attributes when base time did\n",
    "    # not start at 0Z.\n",
    "    # Ignore time zone part (3rd of 3 parts) of \"base_date\" string \n",
    "    # attribute. It used to be \"UTC\" but now it is \"-0:00\".\n",
    "    simple_dt = \" \".join(fh.variables['time'].base_date.split()[0:2])\n",
    "    base_date    = dt.datetime.strptime(simple_dt, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    dt_time = [base_date + dt.timedelta(0,t) for t in fh.variables['time']]\n",
    "\n",
    "    begin_date = dt_time[0].strftime('%Y%m%d')\n",
    "\n",
    "    end_date = dt_time[-1].date() + dt.timedelta(days=1)\n",
    "    end_date = end_date.strftime('%Y%m%d')\n",
    "    fhzeta = fh.variables['zeta']\n",
    "    zeta = fhzeta[:]\n",
    "    units = cf_units.Unit(fhzeta.units)\n",
    "    long_name = fhzeta.long_name\n",
    "    fh.close()\n",
    "\n",
    "    opener = urllib2.build_opener(cache.CacheHandler(\".urllib2cache\"))\n",
    "\n",
    "    for i, station in enumerate(stations[0:]):\n",
    "        id = station.strip()\n",
    "\n",
    "        if (meshlon[i] < lonmin) | (meshlon[i] > lonmax) | (meshlat[i] < latmin) | (meshlat[i] > latmax):\n",
    "            #print id, 'out of bounds'\n",
    "            continue\n",
    "        y = zeta[:,i]\n",
    "        if not y.any():\n",
    "            continue\n",
    "            \n",
    "        print id, \"zeta_max:\", np.ma.max(y)\n",
    "\n",
    "        datum = 'NAVD'\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(turl(id,begin_date,end_date,datum))\n",
    "        except:\n",
    "            print 'failed to read', id, begin_date, end_date, datum,'trying MSL'\n",
    "            datum = 'MSL'\n",
    "            try:\n",
    "                df = pd.read_csv(turl(id,begin_date,end_date,datum))\n",
    "            except:\n",
    "                print 'failed to read', id, begin_date, end_date, datum, 'skipping'\n",
    "                continue\n",
    "        \n",
    "        # strip whitespace from columns\n",
    "        df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "        if isinstance(df['Date Time'][0], str):\n",
    "            msg = df['Date Time'][0]\n",
    "            if 'Error:' in msg:\n",
    "                print msg, \"skipping\", id\n",
    "                continue\n",
    "\n",
    "        waterLevel = df['Water Level']\n",
    "        obs_times = df['Date Time']\n",
    "        if any(waterLevel):\n",
    "\n",
    "            print \"plotting\", station\n",
    "            fig,ax = plt.subplots(1,2,figsize=(16,4))\n",
    "            ax[0].set_ylabel(long_name+\"\\n\"+units.name)\n",
    "            ax[0].grid()\n",
    "            ax[0].plot(dt_time,y,label='ADCIRC')\n",
    "            ax[0].set_title(id)\n",
    "\n",
    "            ax[0].set_xlim(left=dt.datetime.strptime(begin_date,'%Y%m%d'),\n",
    "                           right=dt.datetime.strptime(end_date, '%Y%m%d'))\n",
    "            ax[0].xaxis.set_major_formatter(dates.DateFormatter('%-m/%-d %-H'+'Z'))\n",
    "            ax[0].xaxis.set_major_locator(dates.HourLocator(byhour=[0,12]))\n",
    "            fig.autofmt_xdate()\n",
    "            ax[0].set_xlabel(base_date.strftime(\"%Y\"))\n",
    "            if all(df['Quality'] == 'v'):\n",
    "                ax[0].plot(obs_times,waterLevel,label='observed ('+datum+')')\n",
    "            else:\n",
    "                ax[0].plot(obs_times,waterLevelPreliminary,label='observed ('+datum+')\\npreliminary',alpha=0.5)\n",
    "            ax[0].legend(loc='best')\n",
    "            map_points(ax[1],meshlon[i],meshlat[i])\n",
    "        else:\n",
    "            print \"no water levels\", df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print thisstorm.basedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare control to USGS Sensors (IKE only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False and thisstorm.name == 'IKE':\n",
    "    # USGS stations in Open-File Report 2008-1365\n",
    "    # Monitoring Inland Storm Surge and Flooding from Hurricane Ike in Texas and Louisiana, September 2008\n",
    "    # By Jeffery W. East, Michael J. Turco, and Robert R. Mason, Jr.\n",
    "    stations =[\n",
    "    [\"SSS-TX-BRA-001\", \"Brazoria\", 29.21194, -95.20833, \"surge\"],\n",
    "    [\"SSS-TX-BRA-002\", \"Brazoria\", 29.08472, -95.28806, \"surge\"],\n",
    "    [\"SSS-TX-BRA-004\", \"Brazoria\", 28.86833, -95.44861, \"surge\"],\n",
    "    [\"SSS-TX-BRA-005\", \"Brazoria\", 28.94944, -95.55556, \"riverine\"],\n",
    "    [\"SSS-TX-BRA-006\", \"Brazoria\", 28.86667, -95.58722, \"surge\"],\n",
    "    [\"SSS-TX-BRA-007\", \"Brazoria\", 29.28667, -95.13139, \"riverine\"],\n",
    "    [\"SSS-TX-BRA-008\", \"Brazoria\", 29.03556, -95.39889, \"surge\"],\n",
    "    [\"SSS-TX-BRA-009\", \"Brazoria\", 29.01306, -95.32972, \"surge\"],\n",
    "    [\"SSS-TX-BRA-010\", \"Brazoria\", 29.33639, -95.28417, \"riverine\"],\n",
    "    [\"SSS-TX-BRA-011\", \"Brazoria\", 29.29667, -95.35667, \"riverine\"],\n",
    "    [\"SSS-TX-CAL-001\", \"Calhoun\", 28.40639, -96.71167, \"surge\"],\n",
    "    [\"SSS-TX-CAL-002\", \"Calhoun\", 28.44444, -96.40250, \"surge\"],\n",
    "    [\"SSS-TX-CAL-003\", \"Calhoun\", 28.61917, -96.61972, \"surge\"],\n",
    "    [\"SSS-TX-CAL-004\", \"Calhoun\", 28.66056, -96.41167, \"surge\"],\n",
    "    [\"SSS-TX-CAL-005\", \"Calhoun\", 28.64139, -96.32333, \"surge\"],\n",
    "    [\"SSS-TX-CHA-003\", \"Chambers\", 29.60417, -94.67528, \"surge\"],\n",
    "    [\"SSS-TX-CHA-004\", \"Chambers\", 29.77278, -94.68694, \"surge\"],\n",
    "    [\"SSS-TX-GAL-001\", \"Galveston\", 29.45139, -94.63417, \"beach/wave\"],\n",
    "    [\"SSS-TX-GAL-002\", \"Galveston\", 29.46583, -94.64806, \"surge\"],\n",
    "    [\"SSS-TX-GAL-005\", \"Galveston\", 29.59444, -94.39028, \"surge\"],\n",
    "    [\"SSS-TX-GAL-008\", \"Galveston\", 29.33444, -94.75111, \"beach/wave\"],\n",
    "    [\"SSS-TX-GAL-010\", \"Galveston\", 29.23806, -94.87778, \"beach/wave\"],\n",
    "    [\"SSS-TX-GAL-011\", \"Galveston\", 29.22083, -94.94472, \"surge\"],\n",
    "    [\"SSS-TX-GAL-015\", \"Galveston\", 29.08611, -95.11722, \"beach/wave\"],\n",
    "    [\"SSS-TX-GAL-016\", \"Galveston\", 29.30389, -94.90528, \"surge\"],\n",
    "    [\"SSS-TX-GAL-018\", \"Galveston\", 29.35583, -95.04000, \"surge\"],\n",
    "    [\"SSS-TX-GAL-019\", \"Galveston\", 29.50639, -94.95778, \"surge\"],\n",
    "    [\"SSS-TX-GAL-020\", \"Galveston\", 29.45667, -95.04778, \"riverine\"],\n",
    "    [\"SSS-TX-GAL-021\", \"Galveston\", 29.51333, -95.10389, \"riverine\"],\n",
    "    [\"SSS-TX-GAL-022\", \"Galveston\", 29.55167, -95.02472, \"surge\"],\n",
    "    [\"SSS-TX-HAR-002\", \"Harris\", 29.62028, -94.99889, \"surge_sensor_psige\"],\n",
    "    [\"SSS-TX-HAR-003\", \"Harris\", 29.59194, -95.12833, \"surge\"],\n",
    "    [\"SSS-TX-HAR-004\", \"Harris\", 29.71306, -94.99333, \"surge\"],\n",
    "    [\"SSS-TX-JEF-001\", \"Jefferson\", 29.68444, -94.19278, \"surge\"],\n",
    "    [\"SSS-TX-JEF-002\", \"Jefferson\", 29.67500, -94.04361, \"beach/wave\"],\n",
    "    [\"SSS-TX-JEF-004\", \"Jefferson\", 29.71028, -94.11639, \"surge\"],\n",
    "    [\"SSS-TX-JEF-005\", \"Jefferson\", 29.69694, -94.09833, \"surge\"],\n",
    "    [\"SSS-TX-JEF-006\", \"Jefferson\", 29.71111, -93.86000, \"surge\"],\n",
    "    [\"SSS-TX-JEF-007\", \"Jefferson\", 29.77389, -93.94250, \"surge\"],\n",
    "    [\"SSS-TX-JEF-008\", \"Jefferson\", 29.76472, -93.89778, \"surge\"],\n",
    "    [\"SSS-TX-JEF-009\", \"Jefferson\", 29.66265, -94.08835, \"beach/wave\"],\n",
    "    [\"SSS-TX-MAT-001\", \"Matagorda\", 28.72056, -96.27389, \"surge\"],\n",
    "    [\"SSS-TX-MAT-002\", \"Matagorda\", 28.78639, -96.15028, \"surge\"],\n",
    "    [\"SSS-TX-MAT-003\", \"Matagorda\", 28.78750, -95.99583, \"riverine\"],\n",
    "    [\"SSS-TX-MAT-004\", \"Matagorda\", 28.83889, -95.85278, \"riverine\"],\n",
    "    [\"SSS-TX-MAT-005\", \"Matagorda\", 28.60056, -95.97806, \"beach/wave\"],\n",
    "    [\"SSS-TX-MAT-006\", \"Matagorda\", 28.68306, -95.97556, \"riverine\"],\n",
    "    [\"SSS-TX-MAT-007\", \"Matagorda\", 28.61139, -96.21528, \"surge\"],\n",
    "    [\"SSS-TX-MAT-008\", \"Matagorda\", 28.76417, -95.62694, \"beach/wave\"],\n",
    "    [\"SSS-TX-MAT-009\", \"Matagorda\", 28.77056, -95.61667, \"surge\"],\n",
    "    [\"SSS-TX-MAT-010\", \"Matagorda\", 28.83639, -95.66833, \"riverine\"],\n",
    "    [\"SSS-LA-CAM-001\", \"Cameron\", 29.75028, -93.66361, \"surge\"],\n",
    "    [\"SSS-LA-CAM-002\", \"Cameron\", 29.76194, -93.58250, \"surge\"],\n",
    "    [\"SSS-LA-CAM-003\", \"Cameron\", 29.80417, -93.34889, \"surge\"],\n",
    "    [\"SSS-LA-CAM-010\", \"Cameron\", 29.78611, -93.11500, \"surge\"],\n",
    "    [\"SSS-LA-CAM-011\", \"Cameron\", 29.87056, -93.07972, \"surge\"],\n",
    "    [\"SSS-LA-CAM-012\", \"Cameron\", 29.77056, -93.01444, \"surge\"],\n",
    "    [\"SSS-LA-VER-006\", \"Vermillion\", 29.64111, -92.42694, \"surge\"],\n",
    "    [\"SSS-LA-VER-007\", \"Vermillion\", 29.60028, -92.34167, \"surge\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "    nc_file = thisstorm.basedir+'control/fort.63.nc'\n",
    "    print nc_file\n",
    "    fh = Dataset(nc_file, mode='r')\n",
    "    meshlat = fh.variables['y'][:]\n",
    "    meshlon = fh.variables['x'][:]\n",
    "    mtime   = fh.variables['time']\n",
    "    zeta    = fh.variables['zeta'][:]\n",
    "    base_date = dt.datetime.strptime(mtime.base_date, \"%Y-%m-%d %H:%M:%S %Z\")\n",
    "    dt_time = [base_date+dt.timedelta(0,t) for t in mtime]\n",
    "\n",
    "    units = fh.variables['zeta'].units\n",
    "    long_name = fh.variables['zeta'].long_name\n",
    "    fh.close()\n",
    "\n",
    "    # get scale factor for conversion to feet\n",
    "    newunits = 'feet'\n",
    "    oldunits = cf_units.Unit(units)\n",
    "    sf = oldunits.convert(1,cf_units.Unit(newunits))\n",
    "    units = newunits\n",
    "\n",
    "    for station in stations:\n",
    "        \n",
    "        site = station[0]\n",
    "        lat = station[2]\n",
    "        lon = station[3]\n",
    "        gtype = station[4]\n",
    "        # Find closest node in fort.63.nc\n",
    "        dlat = meshlat - lat\n",
    "        dlon = meshlon - lon\n",
    "        dist = np.sqrt(dlat**2+dlon**2)\n",
    "        i = np.argmin(dist)\n",
    "        y = zeta[:,i] * sf\n",
    "        if y.any():\n",
    "            fig,ax = plt.subplots(1,2,figsize=(16,4))\n",
    "            ax[0].set_ylabel(long_name+\"\\n\"+units)\n",
    "            ax[0].grid()\n",
    "            ax[0].plot(dt_time,y,label='ADCIRC')\n",
    "            ax[0].set_title(site+\"(\"+gtype+\")\")\n",
    "            ax[0].set_xlim(left=dt.datetime(2008,9,11,12),right=dt.datetime(2008,9,14,6))\n",
    "            ax[0].xaxis.set_major_formatter(dates.DateFormatter('%-m/%-d %-H'+'Z'))\n",
    "            ax[0].xaxis.set_major_locator(dates.HourLocator(byhour=[0,12]))\n",
    "            fig.autofmt_xdate()\n",
    "            ax[0].set_xlabel(base_date.strftime(\"%Y\"))\n",
    "\n",
    "            link = \"http://pubs.usgs.gov/of/2008/1365/downloads/ike_\"+site+\".txt\"\n",
    "            obs = np.genfromtxt(link,names=True,dtype=None,skip_header=28)\n",
    "            obs_times = []\n",
    "            elevations = []\n",
    "            for o in obs:\n",
    "                (date, time, elevation, surge_sensor_psi, nearest_barometric_sensor_psi, temp_from_surge_sensor,\n",
    "                temp_from_barometric_sensor, bad_psi_from_surge_sensor,bad_psi_from_barometric_sensor,\n",
    "                bad_temp_from_surge_sensor, bad_temp_from_barometric_sensor) = o\n",
    "                obs_times.append(dt.datetime.strptime(date+time, \"%m-%d-%Y%H:%M\")+dt.timedelta(hours=5)) # CDT time zone\n",
    "                elevations.append(elevation)\n",
    "            ax[0].plot(obs_times,elevations,label='observed')\n",
    "            ax[0].legend(loc='best')\n",
    "            map_points(ax[1],meshlon[i],meshlat[i], marker='o',scalebuffer=0.15,resolution='h')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Perturbations Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# thisstorm must be defined earlier.\n",
    "\n",
    "kwdict = {\n",
    "    \"Ithresh\":'1.00m',\n",
    "    \"minus_astronomical_tide\": False,\n",
    "    \"dryland\" : 'MHHW'\n",
    "}\n",
    "\n",
    "if thisstorm.name == 'HARVEY' and kwdict['minus_astronomical_tide']:\n",
    "    print \"Not interested in stubtracting astronomical tide from Harvey\"\n",
    "    sys.exit(1)\n",
    "    \n",
    "\n",
    "#  veer perturbations\n",
    "veers = Perturbations(thisstorm, ptype='veers', units='km',xlabel='Distance from control at landfall', **kwdict)\n",
    "\n",
    "#  speed perturbations\n",
    "speeds = Perturbations(thisstorm, ptype='speeds',units='km',xlabel=\"Distance from control at landfall\", **kwdict)\n",
    "\n",
    "#  vmax perturbations\n",
    "vmaxes = Perturbations(thisstorm, ptype='vmaxes',units=\"kts\",xlabel = \"Intensity change at landfall\", **kwdict)\n",
    "\n",
    "#  rmax perturbations\n",
    "rmaxes = Perturbations(thisstorm, ptype='rmaxes',units=\"km\",xlabel=\"Change in max. radius of 34-kt wind at landfall\", **kwdict)\n",
    "\n",
    "\n",
    "Perturbations_list = [veers, speeds, rmaxes, vmaxes]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series of Inundation Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(sharey=True,sharex=True,ncols=2,nrows=2,figsize=(10,7))\n",
    "\n",
    "for ax, perturbations in zip(axs.flatten(), Perturbations_list):\n",
    "    if len(perturbations) == 0:\n",
    "        print \"no values for \"+perturbations.ptype+\" perturbations\"\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "\n",
    "    ax.set_title(perturbations.ptype)\n",
    "    for pert in perturbations:\n",
    "        line, = ax.plot(pert.time,pert.inund,label=pert.valuelabel,markersize=3)\n",
    "        if pert.value == 0:\n",
    "            line.set_linewidth(3)\n",
    "            line.set_color('k')\n",
    "        if pert.value < 0:\n",
    "            line.set_marker('^')\n",
    "            line.set_markevery(3)\n",
    "\n",
    "\n",
    "    units = 'inundation volume ($\\mathregular{km^3}$)'\n",
    "    ax.set_ylabel(units)\n",
    "\n",
    "    ax.grid()\n",
    "\n",
    "    ax.xaxis.set_major_formatter(dates.DateFormatter('%-m/%-d %-H'+'Z'))\n",
    "    ax.xaxis.set_major_locator(dates.HourLocator(byhour=[0,6,12,18]))\n",
    "    fig.autofmt_xdate()\n",
    "    ax.set_xlabel(perturbations.time[0][0].strftime(\"%Y\"))\n",
    "    \n",
    "    # put legend\n",
    "    ax.legend(loc='best', ncol=2, fontsize=8)\n",
    "\n",
    "plt.suptitle(thisstorm.name)\n",
    "\n",
    "status = mysavfig(oprefix(perturbations) + '_timeseries.png', string = perturbations.desc, **savfig_dict )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisstorm.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum water level percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if thisstorm.name != 'IRMA':\n",
    "    # WARNING\n",
    "    # THIS DOES NOT ISOLATE REGIONS LIKE FLORIDASW\n",
    "    # IT STILL COVERS THE WHOLE LAT/LON BOX\n",
    "\n",
    "    #  I SHOULD SWITCH TO perfect model file instead of looking for it here?\n",
    "    # The perfect model file has the \"regional\" filter applied.\n",
    "\n",
    "    # Don't assume control is called 'control'. It could be 'control_nws19'\n",
    "    i0, = np.where(veers.values == 0)\n",
    "    control_dir = veers.dirnames[i0[0]]\n",
    "    fh = Dataset(control_dir + '/maxele.63.nc', mode='r')\n",
    "    meshlon = fh.variables['x'][:]\n",
    "    meshlat = fh.variables['y'][:]\n",
    "    fh.close()\n",
    "    ibox = (meshlon >= lonmin) & (meshlon <= lonmax) & (meshlat >= latmin) & (meshlat <= latmax)\n",
    "    meshlon = meshlon[ibox]\n",
    "    meshlat = meshlat[ibox]\n",
    "    for perturbations in Perturbations_list:\n",
    "\n",
    "        if len(perturbations) == 0:\n",
    "            print \"no values for \"+perturbations.ptype+\" perturbations\"\n",
    "            continue\n",
    "        fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
    "        ps = np.array([95,99,99.9,100])\n",
    "        for p in ps:\n",
    "            maxele = []\n",
    "            for pert in perturbations:\n",
    "                maxele.append(np.percentile(pert.maxele[ibox],p))\n",
    "            # Used to plot perturbation.values on x-axis. Changed Feb 28, 2017.\n",
    "            line, = ax[0].plot(perturbations.get_xticks(),maxele,marker='o',label='%.1f'%p)\n",
    "        annotate_pts(perturbations, line)\n",
    "\n",
    "        imaxs = []\n",
    "        for pert in perturbations:\n",
    "            t = np.argmax(pert.maxele[ibox])\n",
    "            imaxs.append(t)\n",
    "\n",
    "        ax[0].set_ylabel('max. water level (m)')\n",
    "        ax[0].set_title(\"Percentiles of Max. Water Level for \"+thisstorm.name+\"\\n\"+thisstorm.domain)\n",
    "        ax[0].yaxis.grid()\n",
    "        ax[0].set_ylim(0,12)\n",
    "        legend = ax[0].legend(loc='best', fontsize=12)\n",
    "        ax[0].set_xlabel(perturbations.xlabel)\n",
    "        zeroLine(line)\n",
    "        forecast_err_boxes(ax[0],perturbations)\n",
    "\n",
    "        m = map_points(ax[1], meshlon[imaxs], meshlat[imaxs], marker='o', colors=line.get_color(), \n",
    "                       labels=perturbations.valuelabels)\n",
    "        ax[1].set_title('Locations of Max. Water Level for\\n'+perturbations.xlabel)\n",
    "\n",
    "        status = mysavfig(oprefix(perturbations,ptype=True)+ '_maxele.png',string=perturbations.desc, **savfig_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Why do I get \"double\" veer (track) lines,?\n",
    "\n",
    "# maybe you haven't symbolically linked \"control\"\n",
    "# directory to \"track+0\",  \"veer+0\", \"vmax+0\",  \"speed+0\", etc.\n",
    "# No. That did not fix it. I didn't negate distance errors for negative veers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://drive.google.com/open?id=1n58sZmEkW0J1YR9DRvasOQwQpp2Ojwvm0fI3VBQTk_k\">Google Doc about length scale</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(sharey=True,ncols=2,nrows=2,figsize=(10,7))\n",
    "\n",
    "for ax, perturbations in zip(axs.flatten(), Perturbations_list):\n",
    "    if len(perturbations) == 0:\n",
    "        print \"no values for \"+perturbations.ptype+\" perturbations\"\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "\n",
    "    thisline, = ax.plot(perturbations.get_xticks(),perturbations.length_scale,marker='o')\n",
    "    annotate_pts(perturbations, thisline)\n",
    "    ax.set_ylabel('length scale (km)')\n",
    "    ax.set_title(perturbations.ptype)\n",
    "    ax.yaxis.grid()\n",
    "    ax.set_xlabel(perturbations.xlabel)\n",
    "    zeroLine(thisline)\n",
    "    forecast_err_boxes(ax, perturbations)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(thisstorm.name)\n",
    "\n",
    "status = mysavfig(oprefix(perturbations)+'_length_scale.png',string=perturbations.desc, **savfig_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area of Inundation Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(sharey=True,ncols=2,nrows=2,figsize=(10,7))\n",
    "\n",
    "for ax, perturbations in zip(axs.flatten(), Perturbations_list):\n",
    "    if len(perturbations) == 0:\n",
    "        print \"no values for \"+perturbations.ptype+\" perturbations\"\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "\n",
    "    # use comma after thisline to \"un-list\" the one-item list of line objects\n",
    "    thisline, = ax.plot(perturbations.get_xticks(),perturbations.area,marker='o')\n",
    "    annotate_pts(perturbations, thisline)\n",
    "    ax.set_ylabel('area of inundation zone\\n$\\mathregular{km^2}$')\n",
    "    ax.set_title(perturbations.ptype)\n",
    "    ax.yaxis.grid()\n",
    "    ax.set_xlabel(perturbations.xlabel)\n",
    "    zeroLine(thisline)\n",
    "    forecast_err_boxes(ax, perturbations)\n",
    "\n",
    "plt.suptitle(thisstorm.name)\n",
    "plt.tight_layout()\n",
    "\n",
    "status = mysavfig(oprefix(perturbations)+'_area.png',string=perturbations.desc, **savfig_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Depth in Inundation Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(sharey=True,ncols=2,nrows=2,figsize=(10,7))\n",
    "\n",
    "for ax, perturbations in zip(axs.flatten(),Perturbations_list):\n",
    "    if len(perturbations) == 0:\n",
    "        print \"no values for \"+perturbations.ptype+\" perturbations\"\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "\n",
    "    thisline, = ax.plot(perturbations.get_xticks(),perturbations.depth,marker='o')\n",
    "    ax.set_ylabel('avg. depth in inundation zone\\nm')\n",
    "    annotate_pts(perturbations, thisline)\n",
    "    ax.set_title(perturbations.ptype)\n",
    "    ax.yaxis.grid()\n",
    "    ax.set_xlabel(perturbations.xlabel)\n",
    "    zeroLine(thisline)\n",
    "    forecast_err_boxes(ax, perturbations)\n",
    "\n",
    "plt.suptitle(thisstorm.name)\n",
    "plt.tight_layout()\n",
    "\n",
    "status = mysavfig(oprefix(perturbations)+'_depth.png',string=perturbations.desc, **savfig_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storm following/Control zone Max. Inundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(sharey=True,ncols=2,nrows=2,figsize=(10,7.))\n",
    "\n",
    "for ax, perturbations in zip(axs.flatten(), Perturbations_list):\n",
    "    if len(perturbations) == 0:\n",
    "        print \"no values for \"+perturbations.ptype+\" perturbations\"\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "\n",
    "    storm_following_line, = ax.plot(perturbations.get_xticks(),perturbations.max_vol, marker='o',label='storm-following')\n",
    "    fixed_location_line, = ax.plot(perturbations.get_xticks(),perturbations.max_vol_in_ctrl, marker='o',label='fixed location')\n",
    "    if perturbations.next().fixed_time: # is this okay? calling next() to get one element from generator?\n",
    "        fixed_location_line.set_label(fixed_location_line.get_label() + ', fixed time')\n",
    "    ax.set_ylabel('inundation volume ($\\mathregular{km^3}$)')\n",
    "    ax.set_title(perturbations.ptype)\n",
    "    ax.set_xlabel(perturbations.xlabel)\n",
    "    zeroLine(storm_following_line,alpha=0.4)\n",
    "    zeroLine(fixed_location_line,alpha=0.4)\n",
    "    forecast_err_boxes(ax, perturbations)\n",
    "    ax.yaxis.grid()\n",
    "\n",
    "    \n",
    "    # Of the 2 lines, label the one with greater mean values    \n",
    "    if np.mean(perturbations.max_vol) > np.mean(perturbations.max_vol_in_ctrl):\n",
    "        annotate_pts(perturbations, storm_following_line)\n",
    "    else:\n",
    "        annotate_pts(perturbations, fixed_location_line)\n",
    "\n",
    "# put legend to the right of the current axis\n",
    "axs[0][0].legend(loc='best')\n",
    "plt.suptitle(thisstorm.name)\n",
    "plt.tight_layout()\n",
    "\n",
    "status = mysavfig(oprefix(perturbations)+'_maxvol.png',string=perturbations.desc, **savfig_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All storms on same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = veers\n",
    "kwdict['xlabel'] = P.xlabel\n",
    "kwdict['ptype'] =  P.ptype\n",
    "kwdict['minus_astronomical_tide'] = False\n",
    "\n",
    "IKEp     = Perturbations(IKE,     **kwdict)\n",
    "CHARLEYp = Perturbations(CHARLEY, **kwdict)\n",
    "CHARIKEp = Perturbations(CHARIKE, **kwdict)\n",
    "IRMAp    = Perturbations(IRMA_SW,    **kwdict)\n",
    "HARVEYp  = Perturbations(HARVEY,  **kwdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for perturbations in [IKEp, CHARLEYp, IRMAp, HARVEYp]:\n",
    "    x = perturbations.get_xticks()\n",
    "    ic, = np.where(np.isclose(x,0))\n",
    "    controly = perturbations.max_vol[ic[0]]\n",
    "    x = 1.+perturbations.values/100.\n",
    "    if perturbations.ptype == 'vmaxes':\n",
    "        norm = perturbations.storm.landfall['vmax']\n",
    "        x = perturbations.get_xticks()/norm\n",
    "    storm_following_line, = ax.plot(x,perturbations.max_vol/controly, \n",
    "                                    marker='o',label=perturbations.storm.name)\n",
    "    ax.set_ylabel('normalized inundation volume')\n",
    "    ax.set_title('storm-following')\n",
    "    ax.set_xlabel('normalized '+perturbations.ptype)\n",
    "\n",
    "ax.grid(True)\n",
    "# put legend to the right of the current axis\n",
    "ax.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "\n",
    "status = mysavfig('all_storms.'+perturbations.ptype+'.maxvol.png',string=perturbations.desc, **savfig_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All storms' r^2, Bias, Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for perturbations in [IKEp, CHARLEYp, CHARIKEp, IRMAp, HARVEYp]:\n",
    "    if len(perturbations) == 0:\n",
    "        print \"no values for \"+perturbations.ptype+\" perturbations\"\n",
    "        continue\n",
    "\n",
    "    r2 = []\n",
    "    bias = []\n",
    "    rmse = []\n",
    "\n",
    "    for pdir in perturbations.dirnames:\n",
    "        # for consistency I started outputting all file names with stride, even\n",
    "        # the perfect_cntl.ncl script. That is always stride01, hence the\n",
    "        # change here.\n",
    "        search_domain = re.sub(r'stride\\d\\d', 'stride01', perturbations.domain)\n",
    "        search_str = pdir + '/*minus_astronomical_tide' + str(perturbations.minus_astronomical_tide) +\\\n",
    "            '_' + perturbations.Ithresh + '.' + perturbations.dryland + '.' + search_domain +\\\n",
    "            '.perfectmodel.nc'\n",
    "        if len(glob.glob(search_str)) == 0:\n",
    "            print 'Found no files matching', search_str\n",
    "        for nc_file in glob.glob(search_str):\n",
    "\n",
    "            print 'reading '+nc_file,\n",
    "            fh = Dataset(nc_file, mode='r')\n",
    "            r2.append(fh.variables['r2'][:])\n",
    "            yave = np.mean(fh.variables['model'])\n",
    "            xave = np.mean(fh.variables['obs'])\n",
    "            bias.append(yave/xave)\n",
    "            obs = fh.variables['obs'][:] # tried np.asarray() but it removed _FillValue\n",
    "            model = fh.variables['model'][:]\n",
    "            rmse.append(np.sqrt(np.mean((obs - model)**2)))\n",
    "            fh.close()\n",
    "\n",
    "    print perturbations.values, r2\n",
    "    r2p, = ax.plot(perturbations.get_xticks(),r2,label=perturbations.storm.name,marker='o')\n",
    "\n",
    "ax.set_ylabel('Correlation Coefficient ($\\mathregular{r^2}$)')\n",
    "\n",
    "ax.set_xlabel(perturbations.xlabel)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.suptitle(perturbations.ptype)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "status = mysavfig('all_storms.'+perturbations.ptype+'.stats.png',bbox_inches='tight',\n",
    "                      string=perturbations.desc, **savfig_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variability at a single point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbations = veers\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,5))\n",
    "colors=[]\n",
    "lons=[]\n",
    "lats=[]\n",
    "nodes = [i['index'] for i in perturbations.pointA]\n",
    "As, i = np.unique(nodes, return_index=True)\n",
    "# convert list to numpy array to index with a slice of indices (i)\n",
    "for pointA in np.array(perturbations.pointA)[i]:\n",
    "    A = pointA['index']\n",
    "    lon = pointA['lon']\n",
    "    lat = pointA['lat']\n",
    "    a = []\n",
    "    for mxfile in perturbations.mxfile:\n",
    "        fh = Dataset(mxfile, mode='r')\n",
    "        zeta_max = fh.variables['zeta_max']\n",
    "        a.append(zeta_max[A])\n",
    "        fh.close()\n",
    "\n",
    "    line, = ax[0].plot(perturbations.get_xticks(), a, marker='x', markeredgewidth=2, label=str(A)+' (%.2fN ' % lat + '%.2fE)' % lon)\n",
    "    zeroLine(line)\n",
    "\n",
    "    colors.append(line.get_color())\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "m = map_points(ax[1], lons, lats, marker='x', colors=colors, linewidth=2, scalebuffer=0.5)\n",
    "\n",
    "\n",
    "#ax[0].legend(loc='best',fontsize=8)\n",
    "ax[0].set_title(thisstorm.name)\n",
    "ax[0].set_xlabel(perturbations.xlabel)\n",
    "forecast_err_boxes(ax[0], perturbations)\n",
    "ax[0].yaxis.grid()\n",
    "ax[0].set_ylim(0, pointA['thresh'])\n",
    "ax[0].set_ylabel('max. inundation depth (m)')\n",
    "\n",
    "for dirname in veers.dirnames:\n",
    "    nc_file = dirname + '/fort.22'\n",
    "    lat0, lon0 = np.genfromtxt(nc_file,delimiter=',', usecols=(6,7),dtype=None, unpack=True)\n",
    "    lat0 = [int(i[:-1])/10. for i in lat0]\n",
    "    lon0 = [int(i[:-1])/ -10. for i in lon0]\n",
    "    m.plot(lon0, lat0, 'black', latlon=True, label=nc_file[70:74],linewidth=(3 if 'control' in nc_file else .71))\n",
    "\n",
    "\n",
    "\n",
    "status = mysavfig(oprefix(perturbations,ptype=True)+'_pointA_maxvol.png',string=perturbations.desc, **savfig_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
